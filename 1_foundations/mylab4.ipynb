{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46706d63",
   "metadata": {},
   "source": [
    "### <b>The first big project - Professionally You!</b> (Career Alter Ego)\n",
    "\n",
    "<b> And, Tool use. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cbabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import json, os, requests, gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14038cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual start\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304bcf8",
   "metadata": {},
   "source": [
    "### <b>Pushover setup</b>\n",
    "\n",
    "Pushover is a nifty tool for sending Push Notifications to your phone.\n",
    "\n",
    "Make sure to include PUSHOVER_USER and PUSHOVER_TOKEN in `.env` file and run `load_dotenv(override=True)` \n",
    "after saving, to set the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "if pushover_user:\n",
    "    print(f\"Pushover user is set and starts with: {pushover_user[0]}\")\n",
    "else:\n",
    "    print(\"Pushover user is not set\")\n",
    "\n",
    "if pushover_token:\n",
    "    print(f\"Pushover token is set and starts with: {pushover_token[0]}\")\n",
    "else:\n",
    "    print(\"Pushover token is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send a push notification\n",
    "\n",
    "def send_push_notification(message):\n",
    "    payload = {\n",
    "        \"token\": pushover_token,\n",
    "        \"user\": pushover_user,\n",
    "        \"message\": message\n",
    "    }\n",
    "    requests.post(pushover_url, data=payload)\n",
    "    \n",
    "    print(f\"Push notification sent: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_push_notification(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90edf548",
   "metadata": {},
   "source": [
    "### <b>Tools setup</b>\n",
    "\n",
    "Now, we will define two functions intended for different purposes, so that they can be used as tools by the LLM\n",
    "\n",
    "To achieve this, we need to have tool definitions in JSON format for the LLM to understand the details. Once defined, we will package them into a tools list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3976b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record details of user that is interested in being in touch\n",
    "\n",
    "def record_user_details(email, name=\"not provided\", notes=\"not provided\"):\n",
    "    \"\"\"Records details of a user who is interested in being in touch.\"\"\"\n",
    "    if not email:\n",
    "        return \"Error: Email is required to record user details.\"\n",
    "\n",
    "    send_push_notification(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "\n",
    "    # Return a simple string to confirm success\n",
    "    return f\"Successfully logged details for {name} ({email}).\"    \n",
    "\n",
    "# Function to record unanswered questions\n",
    "\n",
    "def record_unanswered_question(question):\n",
    "    \"\"\"Records a user's question that the model could not answer.\"\"\"\n",
    "\n",
    "    if not question:\n",
    "        return \"Error: No question was provided to record.\"\n",
    "\n",
    "    send_push_notification(f\"Recording this question that I couldn't answer: {question}\")\n",
    "\n",
    "    # Return a simple string to confirm success\n",
    "    return f\"Successfully logged question: {question}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03682e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definitions in JSON format\n",
    "#\n",
    "# Using UPPER_SNAKE_CASE, as these are module-level constants.\n",
    "# The suffix \"_TOOL\" clearly states their purpose.\n",
    "\n",
    "RECORD_USER_DETAILS_TOOL = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Records details of a user who is interested in being in touch.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's email address.\",\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name.\",\n",
    "            },\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional notes the user provided.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False \n",
    "    }\n",
    "}\n",
    "\n",
    "RECORD_UNANSWERED_QUESTION_TOOL = {\n",
    "    \"name\": \"record_unanswered_question\",\n",
    "    \"description\": \"Always use this tool to record any question that the user asked but couldn't be answered.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question that couldn't be answered\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the Final Tools List\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": RECORD_USER_DETAILS_TOOL},\n",
    "    {\"type\": \"function\", \"function\": RECORD_UNANSWERED_QUESTION_TOOL}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can take a list of tool calls from the LLM, and run them. This is the IF statement!!\n",
    "\n",
    "def handle_tool_calls_OLD(tool_calls):\n",
    "    \"\"\"\n",
    "    Takes a list of tool_calls from an OpenAI response, executes them,\n",
    "    and returns a list of \"tool\" messages.\n",
    "    \"\"\"\n",
    "    tool_output = []\n",
    "\n",
    "    function_map = {\n",
    "        'record_user_details': record_user_details,\n",
    "        'record_unanswered_question': record_unanswered_question\n",
    "    }\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "\n",
    "        function_name = tool_call.function.name\n",
    "        # 1. Parse the JSON string of arguments\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"Tool called: {function_name}\", flush=True)\n",
    "\n",
    "        # Get the function to call based on the function name\n",
    "        # THE BIG IF STATEMENT!!!\n",
    "        \"\"\"\n",
    "        if function_name == \"record_user_details\":\n",
    "            result = record_user_details(**function_args)\n",
    "        elif function_name == \"record_unknown_question\":\n",
    "            result = record_unanswered_question(**function_args)\n",
    "        \"\"\"\n",
    "\n",
    "        function_to_call = function_map[function_name]\n",
    "\n",
    "        # 2. Call the function using ** to unpack the dictionary as arguments\n",
    "        function_response = function_to_call(**function_args)\n",
    "\n",
    "        tool_output.append({\"role\": \"tool\",\"tool_call_id\": tool_call.id,\"content\": json.dumps(function_response)})\n",
    "\n",
    "    return tool_output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f97c7",
   "metadata": {},
   "source": [
    "Instead of using the If statement or the function map dictionary, we can use Python's <b>global()</b> function\n",
    "to find the function to call, based on the incoming tool name\n",
    "\n",
    "<b>global()</b> is a built-in Python function that returns a dictionary of all global names (variables, functions, classes, etc.) that exist in the current module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d519d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the function name from globals\n",
    "print(globals()[\"record_unanswered_question\"])\n",
    "\n",
    "# execute the function. This sends a push notification\n",
    "globals()[\"record_unanswered_question\"](\"This is a really tough question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d265651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a more elegant way that avoids the IF statement/function.\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Takes a list of tool_calls from an OpenAI response, executes them,\n",
    "    and returns a list of \"tool\" messages.\n",
    "    \"\"\"\n",
    "    tool_output = []\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the function name and the function to call\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = globals().get(function_name)\n",
    "\n",
    "        if not function_to_call:\n",
    "            # Handle cases where the model tries to call a function that doesn't exist\n",
    "            function_response = f\"Error: Function '{function_name}' not found.\"\n",
    "        else:\n",
    "            try:\n",
    "                # 1. Parse the JSON string of arguments\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                # 2. Call the function using ** to unpack the dictionary as arguments\n",
    "                print(f\"Tool called: {function_name}\", flush=True)\n",
    "                function_response = function_to_call(**function_args)\n",
    "            except Exception as e:\n",
    "                # Handle any errors during function execution\n",
    "                function_response = f\"Error executing {function_name}: {str(e)}\"\n",
    "\n",
    "        tool_output.append({\"role\": \"tool\",\"tool_call_id\": tool_call.id,\"content\": json.dumps(function_response)})\n",
    "\n",
    "    return tool_output     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32948f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the person the chatbot is representing\n",
    "# This is used to personalize the chatbot's responses\n",
    "name = \"Ed Donner\"\n",
    "\n",
    "# Read the LinkedIn PDF file using the pypdf library\n",
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin_text = \"\"\n",
    "\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin_text += text\n",
    "\n",
    "# Read the summary of the person the chatbot is representing\n",
    "# This is used to provide context to the chatbot's responses\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacce871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt for the chatbot which uses GPT-4o-mini model\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, use your record_unanswered_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin_text}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # This is the call to the LLM - see that we pass in the tools json\n",
    "\n",
    "        response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, tools=tools)\n",
    "\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        # response_message = response.choices[0].message\n",
    "\n",
    "        # messages.append(response_message)\n",
    "        \n",
    "        # If the LLM wants to call a tool, we do that!\n",
    "         \n",
    "        if finish_reason==\"tool_calls\":\n",
    "            response_message = response.choices[0].message\n",
    "            tool_calls = response_message.tool_calls\n",
    "            tool_outputs = handle_tool_calls(tool_calls)\n",
    "            messages.append(response_message)\n",
    "            messages.extend(tool_outputs)\n",
    "        else:\n",
    "            done = True\n",
    "    return response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a523ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
